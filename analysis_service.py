# analysis_service.py
import google.generativeai as genai
import json
from typing import List, Dict

import config

class AnalysisService:
    def __init__(self):
        # 初始化 Google Gemini Client
        genai.configure(api_key=config.GOOGLE_API_KEY)
        self.model = genai.GenerativeModel(config.GENERATIVE_MODEL)

    def get_ai_detection_score(self, text: str) -> float:
        """
        【已修改】使用 Gemini API 判斷文字是否由 AI 生成。
        回傳一個代表「AI 生成機率」的分數 (0.0 到 1.0)。
        """
        print("  - 正在使用 Gemini 進行 AI 生成內容分析...")
        
        # 設計一個專門用於判斷 AI 生成內容的提示 (Prompt)
        prompt = f"""
        Analyze the following text and determine the probability that it was generated by a large language model (like GPT, Gemini, etc.).

        Consider factors such as lexical diversity, syntactic complexity, unnatural phrasing, excessive use of certain words, and overall coherence.

        Provide your answer as a single JSON object with one key: "ai_generated_probability", which should be a float value between 0.0 (definitely human-written) and 1.0 (definitely AI-generated).

        Text to analyze:
        \"\"\"
        {text}
        \"\"\"

        JSON output:
        """
        
        try:
            # 呼叫 Gemini API
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    response_mime_type="application/json",
                    temperature=0.0 # 使用低溫模式以獲得更穩定的判斷
                )
            )
            # 清理並解析 Gemini 回傳的 JSON
            cleaned_json = response.text.strip().lstrip("```json").rstrip("```")
            result = json.loads(cleaned_json)
            
            # 從結果中提取機率分數，如果找不到則回傳 0
            score = float(result.get("ai_generated_probability", 0.0))
            return score
        except Exception as e:
            print(f"  - AI 檢測失敗: {e}")
            # 如果 API 呼叫失敗，回傳一個中性或低分數，避免誤判
            return 0.0

    def generate_search_queries(self, text: str) -> List[str]:
        """使用 Gemini 從段落中提取適合網路搜尋的關鍵詞組。"""
        prompt = f"""
        Extract up to 3 distinct, concise web-search queries (max 32 tokens each) 
        that would be most effective at finding the original source of the following text.
        Focus on unique terminology, proper nouns, and key phrases. 
        Return the queries as a JSON list of strings in a JSON object with a "queries" key.

        Text:
        \"\"\"
        {text}
        \"\"\"

        JSON output:
        """
        try:
            # 使用 Gemini API
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    response_mime_type="application/json",
                    temperature=0.0
                )
            )
            # Gemini 回傳的 content 可能包含 Markdown 標籤，需要清理
            cleaned_json = response.text.strip().lstrip("```json").rstrip("```")
            queries = json.loads(cleaned_json)
            # 確保輸出是列表
            return queries.get("queries", []) if isinstance(queries, dict) else queries
        except Exception as e:
            print(f"查詢生成失敗: {e}")
            # Fallback: 使用簡單的文字切片
            return [text[:128]]

    def get_llm_adjudication(self, suspect_chunk: str, hit_chunk: str, source_url: str, ai_score: float) -> Dict:
        """模組 3: LLM 裁決層，使用 Gemini 綜合所有證據進行判斷。"""
        prompt = f"""
        You are an academic integrity adjudicator. Based on the following data, determine if the student's paragraph is likely AI-generated or plagiarized from a web source without proper citation.

        Data:
        - Student's Paragraph: "<<<{suspect_chunk}>>>"
        - AI-Detector Score: {ai_score:.2f} (A score closer to 1.0 means more likely AI-generated)
        - Highly Similar Candidate Paragraph: "<<<{hit_chunk}>>>"
        - Source URL: {source_url}

        Instructions:
        Analyze all pieces of evidence. A high AI score suggests AI origin. High similarity to a web source suggests plagiarism.
        Provide your final judgment in a single JSON object with the following keys:
        - "ai_generated": boolean, is it likely generated by AI?
        - "web_plagiarism": boolean, is it likely plagiarized from the web source?
        - "confidence": float (0.0-1.0), your confidence in this overall judgment.
        - "justification": string, a brief explanation for your decision, referencing the evidence.
        """
        try:
            # 使用 Gemini API
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    response_mime_type="application/json",
                    temperature=0.1
                )
            )
            cleaned_json = response.text.strip().lstrip("```json").rstrip("```")
            return json.loads(cleaned_json)
        except Exception as e:
            print(f"LLM 裁決失敗: {e}")
            return {"verdict": "裁決失敗", "reason": str(e), "confidence": 0.0}