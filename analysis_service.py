# analysis_service.py
import openai
import json
from typing import List, Dict

import config

class AnalysisService:
    def __init__(self):
        self.client = openai.OpenAI(api_key=config.OPENAI_API_KEY)

    def get_ai_detection_score(self, text: str) -> float:
        """
        (MVP) 呼叫第三方 AI 檢測 API 或自建模型。
        此處為假想實作，回傳一個隨機分數。
        """
        # 實際應用中，你會呼叫如 GPTZero 的 API
        # response = requests.post("https://api.gptzero.me/v2/predict/text", json={"document": text}, headers={"X-Api-Key": "YOUR_GPTZERO_KEY"})
        # return response.json()['documents'][0]['completely_generated_prob']
        print("注意: AI 檢測分數為模擬值。")
        import random
        return random.uniform(0.1, 0.9)

    def generate_search_queries(self, text: str) -> List[str]:
        """使用 LLM 從段落中提取適合網路搜尋的關鍵詞組。"""
        prompt = f"""
        Extract up to 3 distinct, concise web-search queries (max 32 tokens each) 
        that would be most effective at finding the original source of the following text.
        Focus on unique terminology, proper nouns, and key phrases. 
        Return the queries as a JSON list of strings.

        Text:
        \"\"\"
        {text}
        \"\"\"

        JSON output:
        """
        try:
            response = self.client.chat.completions.create(
                model=config.QUERY_GENERATION_MODEL,
                messages=[{"role": "system", "content": "You are a search query generation expert."},
                          {"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.0
            )
            queries = json.loads(response.choices[0].message.content)
            # 確保輸出是列表
            return queries.get("queries", []) if isinstance(queries, dict) else queries
        except Exception as e:
            print(f"查詢生成失敗: {e}")
            # Fallback: 使用簡單的文字切片
            return [text[:128]]

    def get_llm_adjudication(self, suspect_chunk: str, hit_chunk: str, source_url: str, ai_score: float) -> Dict:
        """模組 3: LLM 裁決層，綜合所有證據進行判斷。"""
        prompt = f"""
        You are an academic integrity adjudicator. Based on the following data, determine if the student's paragraph is likely AI-generated or plagiarized from a web source without proper citation.

        Data:
        - Student's Paragraph: "<<<{suspect_chunk}>>>"
        - AI-Detector Score: {ai_score:.2f} (A score closer to 1.0 means more likely AI-generated)
        - Highly Similar Candidate Paragraph: "<<<{hit_chunk}>>>"
        - Source URL: {source_url}

        Instructions:
        Analyze all pieces of evidence. A high AI score suggests AI origin. High similarity to a web source suggests plagiarism.
        Provide your final judgment in a single JSON object with the following keys:
        - "ai_generated": boolean, is it likely generated by AI?
        - "web_plagiarism": boolean, is it likely plagiarized from the web source?
        - "confidence": float (0.0-1.0), your confidence in this overall judgment.
        - "justification": string, a brief explanation for your decision, referencing the evidence.
        """
        try:
            response = self.client.chat.completions.create(
                model=config.LLM_ADJUDICATOR_MODEL,
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.1
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"LLM 裁決失敗: {e}")
            return {"verdict": "裁決失敗", "reason": str(e), "confidence": 0.0}